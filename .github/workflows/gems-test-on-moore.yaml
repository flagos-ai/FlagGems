---
name: unittest-moore

'on':
  push:
    branches: ["master"]
    paths:
      - 'src/flag_gems/runtime/backend/_mthreads/**'
      - 'tests/**'
      - 'tools/gpu_check_moore.sh'
      - '.github/workflows/gems-test-on-moore.yaml'
      - '**.py'
      - '**.cpp'
      - '**.cu'
      - '**.h'
      - '**.hpp'
      - '**.cc'
      - 'CMakeLists.txt'
      - '**/*.cmake'
      - '**/*.mk'
      - 'Makefile'
      - '!src/flag_gems/experimental_ops/**'
      - '!experimental_tests/**'
      - '!src/flag_gems/runtime/backend/_nvidia/**'
      - '!src/flag_gems/runtime/backend/_iluvatar/**'
      - '!src/flag_gems/runtime/backend/_cambricon/**'
      - '!src/flag_gems/runtime/backend/_hygon/**'
      - '!src/flag_gems/runtime/backend/_metax/**'

  pull_request:
    branches: ["master"]
    paths:
      - 'src/flag_gems/runtime/backend/_mthreads/**'
      - 'tests/**'
      - 'tools/gpu_check_moore.sh'
      - '.github/workflows/gems-test-on-moore.yaml'
      - '**.py'
      - '**.cpp'
      - '**.cu'
      - '**.h'
      - '**.hpp'
      - '**.cc'
      - 'CMakeLists.txt'
      - '**/*.cmake'
      - '**/*.mk'
      - 'Makefile'
      - '!src/flag_gems/experimental_ops/**'
      - '!experimental_tests/**'
      - '!src/flag_gems/runtime/backend/_nvidia/**'
      - '!src/flag_gems/runtime/backend/_iluvatar/**'
      - '!src/flag_gems/runtime/backend/_cambricon/**'
      - '!src/flag_gems/runtime/backend/_hygon/**'
      - '!src/flag_gems/runtime/backend/_metax/**'

jobs:
  op-test-on-moore:
    runs-on: mthreadsCI
    concurrency:
      group: >
        op-test-on-moore-${{ github.event.pull_request.number || github.ref }}
      cancel-in-progress: true
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Check Moore Threads GPU availability
        shell: bash
        run: |
          bash tools/gpu_check_moore.sh

      - name: FlagGems tensor constructor ops on moore
        shell: bash
        run: |
          source tools/run_command.sh
          GEMS_VENDOR=moore run_command python3 -m pytest -s \
            tests/test_tensor_constructor_ops.py

      - name: FlagGems utils on moore
        shell: bash
        run: |
          source tools/run_command.sh
          GEMS_VENDOR=moore run_command python3 -m pytest -s \
            tests/test_libentry.py && \
          GEMS_VENDOR=moore run_command python3 -m pytest -s \
            tests/test_shape_utils.py && \
          GEMS_VENDOR=moore run_command python3 -m pytest -s \
            tests/test_tensor_wrapper.py

      - name: FlagGems pointwise dynamic ops on moore
        shell: bash
        run: |
          source tools/run_command.sh
          GEMS_VENDOR=moore run_command python3 -m pytest -s \
            tests/test_pointwise_dynamic.py

      - name: FlagGems distribution ops on moore
        shell: bash
        run: |
          source tools/run_command.sh
          GEMS_VENDOR=moore run_command python3 -m pytest -s \
            tests/test_distribution_ops.py

      # FIXME(moore): Softmax only support float32/float16/bfloat16
      # GEMS_VENDOR=moore run_command python3 -m pytest -s \
      #   tests/test_reduction_ops.py
      # FIXME(moore): BatchNorm supports Float/Half/BFloat16 input dtype
      # GEMS_VENDOR=moore run_command python3 -m pytest -s \
      #   tests/test_norm_ops.py
      # FIXME(moore): RuntimeError: _Map_base::at (missing operators)
      # GEMS_VENDOR=moore run_command python3 -m pytest -s \
      #   tests/test_unary_pointwise_ops.py
      # FIXME(moore): unsupported data type DOUBLE
      # GEMS_VENDOR=moore run_command python3 -m pytest -s \
      #   tests/test_blas_ops.py
