import torch
import sys
sys.path.append(".")  # æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„
from operator.log10_ops import log10, log10_, log10_out

def test_precision():
    """ç²¾åº¦éªŒè¯ï¼šä¸ PyTorch åŸç”Ÿ log10 å¯¹æ¯”ï¼Œè¯¯å·® < 1e-6"""
    # æµ‹è¯•å¤šç»´åº¦ã€å¤šæ•°å€¼åœºæ™¯
    test_cases = [
        torch.tensor([1.0, 10.0, 100.0, 0.1, 2.0], dtype=torch.float32),
        torch.tensor([1000.0, 0.01, 5.0], dtype=torch.float64),
        torch.randn((5, 5), dtype=torch.float32).abs() + 0.1,  # éšæœºæ­£æ•°å¼ é‡
        torch.randn((2, 3, 4), dtype=torch.float64).abs() + 0.1
    ]
    
    for idx, x in enumerate(test_cases):
        # æ™®é€šç‰ˆéªŒè¯
        my_log10 = log10(x)
        torch_log10 = torch.log10(x)
        assert torch.allclose(my_log10, torch_log10, atol=1e-6), \
            f"æ™®é€šç‰ˆæµ‹è¯•ç”¨ä¾‹ {idx} ç²¾åº¦ä¸è¾¾æ ‡"
        
        # In-place ç‰ˆéªŒè¯
        x_inplace = x.clone()
        x_torch = x.clone()
        log10_(x_inplace)
        x_torch.log10_()
        assert torch.allclose(x_inplace, x_torch, atol=1e-6), \
            f"In-place ç‰ˆæµ‹è¯•ç”¨ä¾‹ {idx} ç²¾åº¦ä¸è¾¾æ ‡"
        
        # Out ç‰ˆéªŒè¯
        out_my = torch.empty_like(x)
        out_torch = torch.empty_like(x)
        log10_out(x, out=out_my)
        torch.log10(x, out=out_torch)
        assert torch.allclose(out_my, out_torch, atol=1e-6), \
            f"Out ç‰ˆæµ‹è¯•ç”¨ä¾‹ {idx} ç²¾åº¦ä¸è¾¾æ ‡"
    
    print("âœ… æ‰€æœ‰ç²¾åº¦æµ‹è¯•é€šè¿‡ï¼ˆè¯¯å·® < 1e-6ï¼‰")

def test_performance():
    """æ€§èƒ½éªŒè¯ï¼šæµ‹è¯•å¤§å¼ é‡ä¸‹çš„æ‰§è¡Œæ•ˆç‡"""
    # æ¨¡æ‹Ÿç«èµ›æ€§èƒ½æµ‹è¯•åœºæ™¯ï¼ˆ1000x1000 æµ®ç‚¹å¼ é‡ï¼‰
    x = torch.randn((1000, 1000), dtype=torch.float32).abs() + 0.1
    
    # æ™®é€šç‰ˆè€—æ—¶
    torch.cuda.synchronize() if x.is_cuda else None
    if x.is_cuda:
        start = torch.cuda.Event(enable_timing=True)
        start.record()
        log10(x)
        torch.cuda.synchronize()
        end = torch.cuda.Event(enable_timing=True)
        end.record()
        torch.cuda.synchronize()
        print(f"æ™®é€šç‰ˆè€—æ—¶ï¼š{start.elapsed_time(end):.4f} ms")
    else:
        from timeit import timeit
        # CPU ç‰ˆè€—æ—¶ï¼ˆè¿è¡Œ1000æ¬¡å–å¹³å‡ï¼‰
        avg_time = timeit(lambda: log10(x), number=1000) / 1000 * 1000  # è½¬ ms
        print(f"æ™®é€šç‰ˆå¹³å‡è€—æ—¶ï¼š{avg_time:.4f} ms")
    
    print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")

def test_exception():
    """å¼‚å¸¸å¤„ç†éªŒè¯ï¼šç¡®ä¿éæ³•è¾“å…¥è§¦å‘æ­£ç¡®å¼‚å¸¸"""
    # æµ‹è¯•1ï¼šè´Ÿæ•°/é›¶è¾“å…¥è§¦å‘ ValueError
    x = torch.tensor([-1.0, 0.0])
    try:
        log10(x)
        # è‹¥æœªæŠ›å¼‚å¸¸ï¼Œè§¦å‘æ–­è¨€å¤±è´¥
        assert False, "æœªè§¦å‘è´Ÿæ•°/é›¶è¾“å…¥å¼‚å¸¸"
    except ValueError as e:
        # ç¡®è®¤å¼‚å¸¸ä¿¡æ¯åŒ…å«å…³é”®æç¤º
        assert "ä¸¥æ ¼æ­£æ•°å¼ é‡" in str(e), "å¼‚å¸¸ä¿¡æ¯ä¸ç¬¦åˆé¢„æœŸ"
    
    # æµ‹è¯•2ï¼šout å¼ é‡ dtype ä¸åŒ¹é…è§¦å‘ ValueError
    out = torch.empty((2,), dtype=torch.float64)
    x_float32 = torch.tensor([1.0, 10.0], dtype=torch.float32)
    try:
        log10_out(x_float32, out=out)
        assert False, "æœªè§¦å‘ dtype ä¸åŒ¹é…å¼‚å¸¸"
    except ValueError:
        pass
    
    # æµ‹è¯•3ï¼šin-place ç‰ˆè´Ÿæ•°è¾“å…¥è§¦å‘å¼‚å¸¸
    x_inplace = torch.tensor([-5.0])
    try:
        log10_(x_inplace)
        assert False, "in-place ç‰ˆæœªè§¦å‘è´Ÿæ•°è¾“å…¥å¼‚å¸¸"
    except ValueError:
        pass
    
    print("âœ… å¼‚å¸¸å¤„ç†æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    # ä¼˜å…ˆæµ‹è¯• CPUï¼Œå¯é€‰æµ‹è¯• CUDAï¼ˆå¦‚æœ‰ GPUï¼‰
    test_precision()
    test_exception()
    test_performance()
    
    # å¯é€‰ï¼šCUDA æµ‹è¯•ï¼ˆæ³¨é‡Šæ‰ä¹Ÿä¸å½±å“æäº¤ï¼‰
    if torch.cuda.is_available():
        print("\n=== CUDA ç‰ˆæœ¬æµ‹è¯• ===")
        x_cuda = torch.tensor([1.0, 10.0, 100.0], dtype=torch.float32).cuda()
        my_log10_cuda = log10(x_cuda)
        torch_log10_cuda = torch.log10(x_cuda)
        assert torch.allclose(my_log10_cuda, torch_log10_cuda, atol=1e-6)
        print("âœ… CUDA ç‰ˆæœ¬æµ‹è¯•é€šè¿‡")
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼Œå¯æäº¤ç«èµ›ï¼")