import logging

import torch
from packaging import version

from flag_gems import fused, ops, runtime
from flag_gems.config import aten_patch_list

# TODO(Qiming): Remove the following imports, the compiler currenly relies
# on the package path so it cannot be moved.
from flag_gems.fused import moe_align_block_size_triton  # noqa: F401
from flag_gems.logging_utils import setup_flaggems_logging
from flag_gems.runtime.register import Register

__version__ = "4.1"
device = runtime.device.name
vendor_name = runtime.device.vendor_name
aten_lib = torch.library.Library("aten", "IMPL")
registrar = Register
current_work_registrar = None
runtime.replace_customized_ops(globals())


def torch_ge(v):
    return version.parse(torch.__version__) >= version.parse(v)


def enable(
    lib=aten_lib,
    unused=None,
    registrar=registrar,
    record=False,
    once=False,
    path=None,
):
    global current_work_registrar
    current_work_registrar = registrar(
        (
            ("_flash_attention_forward", ops.flash_attention_forward),
            ("_log_softmax", ops.log_softmax),
            ("_log_softmax_backward_data", ops.log_softmax_backward),
            ("_softmax", ops.softmax),
            ("_softmax_backward_data", ops.softmax_backward),
            (
                "_to_copy",
                ops.to_copy,
                lambda: version.parse(torch.__version__) >= version.parse("2.4"),
            ),
            ("_unique2", ops._unique2),
            ("_upsample_bicubic2d_aa", ops._upsample_bicubic2d_aa),
            ("_weight_norm_interface", ops.weight_norm_interface),
            ("_weight_norm_interface_backward", ops.weight_norm_interface_backward),
            ("moe_sum", fused.moe_sum),
            ("abs", ops.abs),
            ("abs_", ops.abs_),
            ("add.Tensor", ops.add),
            ("add_.Tensor", ops.add_),
            ("addcdiv", ops.addcdiv),
            ("addcmul", ops.addcmul),
            ("addmv", ops.addmv),
            ("addmv.out", ops.addmv_out),
            ("addmm", ops.addmm),
            ("addmm.out", ops.addmm_out),
            ("all", ops.all),
            ("all.dim", ops.all_dim),
            ("all.dims", ops.all_dims),
            ("allclose", ops.allclose),
            ("amax", ops.amax),
            ("angle", ops.angle),
            ("any", ops.any),
            ("any.dim", ops.any_dim),
            ("any.dims", ops.any_dims),
            ("arange", ops.arange),
            ("arange.start", ops.arange_start),
            ("arange.start_step", ops.arange_start),
            ("argmax", ops.argmax),
            ("argmin", ops.argmin),
            ("atan", ops.atan),
            ("atan_", ops.atan_),
            ("avg_pool2d", ops.avg_pool2d),
            ("avg_pool2d_backward", ops.avg_pool2d_backward),
            ("baddbmm", ops.baddbmm),
            ("bitwise_and.Scalar", ops.bitwise_and_scalar),
            ("bitwise_and.Scalar_Tensor", ops.bitwise_and_scalar_tensor),
            ("bitwise_and.Tensor", ops.bitwise_and_tensor),
            ("bitwise_and_.Scalar", ops.bitwise_and_scalar_),
            ("bitwise_and_.Tensor", ops.bitwise_and_tensor_),
            ("bitwise_left_shift", ops.bitwise_left_shift),
            ("bitwise_right_shift", ops.bitwise_right_shift),
            ("bitwise_not", ops.bitwise_not),
            ("bitwise_not_", ops.bitwise_not_),
            ("bitwise_or.Scalar", ops.bitwise_or_scalar),
            ("bitwise_or.Scalar_Tensor", ops.bitwise_or_scalar_tensor),
            ("bitwise_or.Tensor", ops.bitwise_or_tensor),
            ("bitwise_or_.Scalar", ops.bitwise_or_scalar_),
            ("bitwise_or_.Tensor", ops.bitwise_or_tensor_),
            ("bmm", ops.bmm),
            ("cat", ops.cat),
            ("celu", ops.celu),
            ("celu_", ops.celu_),
            ("clamp", ops.clamp),
            ("clamp.Tensor", ops.clamp_tensor),
            ("clamp_min", ops.clamp_min),
            ("clamp_", ops.clamp_),
            ("clamp_.Tensor", ops.clamp_tensor_),
            ("clamp_min_", ops.clamp_min_),
            ("constant_pad_nd", ops.constant_pad_nd),
            # ("contiguous", contiguous),
            (
                "copy_",
                ops.copy_,
                lambda: version.parse(torch.__version__) >= version.parse("2.4"),
            ),
            ("cos", ops.cos),
            ("cos_", ops.cos_),
            ("count_nonzero", ops.count_nonzero),
            ("cummax", ops.cummax),
            ("cummin", ops.cummin),
            ("cumsum", ops.cumsum),
            ("cumsum.out", ops.cumsum_out),
            ("diag", ops.diag),
            ("diag_embed", ops.diag_embed),
            ("diagonal_backward", ops.diagonal_backward),
            ("div.Scalar", ops.true_divide),
            ("div.Scalar_mode", ops.div_mode),
            ("div.Tensor", ops.true_divide),
            ("div.Tensor_mode", ops.div_mode),
            ("div.out", ops.true_divide_out),
            ("div_.Scalar", ops.true_divide_),
            ("div_.Scalar_mode", ops.div_mode_),
            ("div_.Tensor", ops.true_divide_),
            ("div_.Tensor_mode", ops.div_mode_),
            ("divide.Scalar", ops.true_divide),
            ("divide.Scalar_mode", ops.div_mode),
            ("divide.Tensor", ops.true_divide),
            ("divide.Tensor_mode", ops.div_mode),
            ("divide_.Scalar", ops.true_divide_),
            ("divide_.Scalar_mode", ops.div_mode_),
            ("divide_.Tensor", ops.true_divide_),
            ("divide_.Tensor_mode", ops.div_mode_),
            ("dot", ops.dot),
            ("elu", ops.elu),
            ("elu_", ops.elu_),
            ("elu_backward", ops.elu_backward),
            ("embedding", ops.embedding),
            ("embedding_backward", ops.embedding_backward),
            ("eq.Scalar", ops.eq_scalar),
            ("eq.Tensor", ops.eq),
            ("erf", ops.erf),
            ("erf_", ops.erf_),
            ("exp", ops.exp),
            ("exp_", ops.exp_),
            ("exp.out", ops.exp_out),
            ("exp2", ops.exp2),
            ("exp2_", ops.exp2_),
            ("exponential_", ops.exponential_),
            ("eye", ops.eye),
            ("eye.m", ops.eye_m),
            ("fill.Scalar", ops.fill_scalar),
            ("fill.Tensor", ops.fill_tensor),
            ("fill_.Scalar", ops.fill_scalar_),
            ("fill_.Tensor", ops.fill_tensor_),
            ("flip", ops.flip),
            ("floor_divide", ops.floor_divide),
            ("floor_divide.Scalar", ops.floor_divide),
            ("floor_divide_.Scalar", ops.floor_divide_),
            ("floor_divide_.Tensor", ops.floor_divide_),
            ("full", ops.full),
            ("full_like", ops.full_like),
            ("gather", ops.gather),
            ("gather_backward", ops.gather_backward),
            ("ge.Scalar", ops.ge_scalar),
            ("ge.Tensor", ops.ge),
            ("gelu", ops.gelu),
            ("gelu_", ops.gelu_),
            ("gelu_backward", ops.gelu_backward),
            ("glu", ops.glu),
            ("glu_backward", ops.glu_backward),
            ("gt.Scalar", ops.gt_scalar),
            ("gt.Tensor", ops.gt),
            ("hstack", ops.hstack),
            ("index.Tensor", ops.index),
            ("index_add", ops.index_add),
            ("index_add_", ops.index_add_),
            ("index_put", ops.index_put),
            ("index_put_", ops.index_put_),
            ("index_select", ops.index_select),
            ("isclose", ops.isclose),
            ("isfinite", ops.isfinite),
            ("isin.Scalar_Tensor", ops.isin),
            ("isin.Tensor_Scalar", ops.isin),
            ("isin.Tensor_Tensor", ops.isin),
            ("isinf", ops.isinf),
            ("isnan", ops.isnan),
            ("kron", ops.kron),
            ("le.Scalar", ops.le_scalar),
            ("le.Tensor", ops.le),
            ("lerp.Scalar", ops.lerp_scalar),
            ("lerp.Tensor", ops.lerp_tensor),
            ("lerp_.Scalar", ops.lerp_scalar_),
            ("lerp_.Tensor", ops.lerp_tensor_),
            ("linalg_vector_norm", ops.vector_norm),
            ("linspace", ops.linspace),
            ("log", ops.log),
            ("log_sigmoid", ops.log_sigmoid),
            ("logical_and", ops.logical_and),
            ("logical_not", ops.logical_not),
            ("logical_or", ops.logical_or),
            ("logical_xor", ops.logical_xor),
            ("logspace", ops.logspace),
            ("lt.Scalar", ops.lt_scalar),
            ("lt.Tensor", ops.lt),
            ("masked_fill.Scalar", ops.masked_fill),
            ("masked_fill.Tensor", ops.masked_fill),
            ("masked_fill_.Scalar", ops.masked_fill_),
            ("masked_fill_.Tensor", ops.masked_fill_),
            ("masked_select", ops.masked_select),
            ("max", ops.max),
            ("max.dim", ops.max_dim),
            ("maximum", ops.maximum),
            ("max_pool2d_with_indices", ops.max_pool2d_with_indices),
            ("max_pool2d_backward", ops.max_pool2d_backward),
            ("mean", ops.mean),
            ("mean.dim", ops.mean_dim),
            ("min", ops.min),
            ("min.dim", ops.min_dim),
            ("minimum", ops.minimum),
            ("mm", ops.mm),
            ("mm.out", ops.mm_out),
            ("mse_loss", ops.mse_loss),
            ("mul.Tensor", ops.mul),
            ("mul_.Tensor", ops.mul_),
            ("multinomial", ops.multinomial),
            ("mv", ops.mv),
            ("nan_to_num", ops.nan_to_num),
            ("native_batch_norm", ops.batch_norm),
            ("native_batch_norm_backward", ops.batch_norm_backward),
            ("native_dropout", ops.dropout),
            ("native_dropout_backward", ops.dropout_backward),
            ("native_group_norm", ops.group_norm),
            ("native_group_norm_backward", ops.group_norm_backward),
            ("native_layer_norm", ops.layer_norm),
            ("native_layer_norm_backward", ops.layer_norm_backward),
            ("ne.Scalar", ops.ne_scalar),
            ("ne.Tensor", ops.ne),
            ("neg", ops.neg),
            ("neg_", ops.neg_),
            ("nll_loss_backward", ops.nll_loss_backward),
            ("nll_loss_forward", ops.nll_loss_forward),
            ("nll_loss2d_backward", ops.nll_loss2d_backward),
            ("nll_loss2d_forward", ops.nll_loss2d_forward),
            ("nonzero", ops.nonzero),
            ("normal.float_Tensor", ops.normal_float_tensor),
            ("normal.Tensor_float", ops.normal_tensor_float),
            ("normal.Tensor_Tensor", ops.normal_tensor_tensor),
            ("ones", ops.ones),
            ("ones_like", ops.ones_like),
            ("pad", ops.pad),
            ("per_token_group_quant_fp8", ops.per_token_group_quant_fp8),
            ("polar", ops.polar),
            ("pow.Scalar", ops.pow_scalar),
            ("pow.Tensor_Scalar", ops.pow_tensor_scalar),
            ("pow.Tensor_Tensor", ops.pow_tensor_tensor),
            ("pow_.Scalar", ops.pow_tensor_scalar_),
            ("pow_.Tensor", ops.pow_tensor_tensor_),
            ("prod", ops.prod),
            ("prod.dim_int", ops.prod_dim),
            ("quantile", ops.quantile),
            ("rand", ops.rand),
            ("rand_like", ops.rand_like),
            ("randn", ops.randn),
            ("randn_like", ops.randn_like),
            ("randperm", ops.randperm),
            ("reciprocal", ops.reciprocal),
            ("reciprocal_", ops.reciprocal_),
            ("relu", ops.relu),
            ("relu_", ops.relu_),
            ("softplus", ops.softplus),
            ("remainder.Scalar", ops.remainder),
            ("remainder.Scalar_Tensor", ops.remainder),
            ("remainder.Tensor", ops.remainder),
            ("remainder_.Scalar", ops.remainder_),
            ("remainder_.Tensor", ops.remainder_),
            ("repeat", ops.repeat),
            ("repeat_interleave.self_int", ops.repeat_interleave_self_int),
            ("repeat_interleave.self_Tensor", ops.repeat_interleave_self_tensor),
            ("repeat_interleave.Tensor", ops.repeat_interleave_tensor),
            ("resolve_conj", ops.resolve_conj),
            ("resolve_neg", ops.resolve_neg),
            ("rms_norm", ops.rms_norm),
            ("sqrt", ops.sqrt),
            ("sqrt_", ops.sqrt_),
            ("rsqrt", ops.rsqrt),
            ("rsqrt_", ops.rsqrt_),
            ("scatter.reduce", ops.scatter),
            ("scatter.src", ops.scatter),
            ("scatter_.reduce", ops.scatter_),
            ("scatter_.src", ops.scatter_),
            ("select_scatter", ops.select_scatter),
            ("sigmoid", ops.sigmoid),
            ("sigmoid_", ops.sigmoid_),
            ("sigmoid_backward", ops.sigmoid_backward),
            ("silu", ops.silu),
            ("silu_", ops.silu_),
            ("silu_backward", ops.silu_backward),
            ("sin", ops.sin),
            ("sin_", ops.sin_),
            ("slice_scatter", ops.slice_scatter),
            ("sort", ops.sort),
            ("sort.stable", ops.sort_stable),
            ("stack", ops.stack),
            ("std.correction", ops.std),
            ("sub.Tensor", ops.sub),
            ("sub_.Tensor", ops.sub_),
            ("sum", ops.sum),
            ("sum.dim_IntList", ops.sum_dim),
            ("sum.IntList_out", ops.sum_dim_out),
            ("sum.out", ops.sum_out),
            ("tanh", ops.tanh),
            ("tanh_", ops.tanh_),
            ("tanh_backward", ops.tanh_backward),
            ("threshold", ops.threshold),
            ("threshold_backward", ops.threshold_backward),
            ("tan", ops.tan),
            ("tan_", ops.tan_),
            ("tile", ops.tile),
            ("topk", ops.topk),
            ("topk_softmax", fused.topk_softmax),
            ("trace", ops.trace),
            ("triu", ops.triu),
            ("true_divide.Scalar", ops.true_divide),
            ("true_divide.Tensor", ops.true_divide),
            ("true_divide_.Scalar", ops.true_divide_),
            ("true_divide_.Tensor", ops.true_divide_),
            ("uniform_", ops.uniform_),
            ("upsample_nearest2d", ops.upsample_nearest2d),
            ("var_mean.correction", ops.var_mean),
            ("vdot", ops.vdot),
            ("addr", ops.addr),
            ("vstack", ops.vstack),
            ("where.ScalarOther", ops.where_scalar_other),
            ("where.ScalarSelf", ops.where_scalar_self),
            ("where.self", ops.where_self),
            ("where.self_out", ops.where_self_out),
            ("zeros", ops.zeros),
            ("zeros_like", ops.zeros_like),
            ("scatter_add_", ops.scatter_add_),
            ("dreglu", fused.dreglu),
            ("reglu", fused.reglu),
            ("scaled_softmax_forward", ops.scaled_softmax_forward),
            ("scaled_softmax_backward", ops.scaled_softmax_backward),
            ("conv1d", ops.conv1d),
            ("conv2d", ops.conv2d),
            ("conv3d", ops.conv3d),
            ("conv1d.padding", ops.conv1d),
            ("conv2d.padding", ops.conv2d),
            ("conv3d.padding", ops.conv3d),
        ),
        user_unused_ops_list=list(set(unused or [])),
        cpp_patched_ops_list=list(set(aten_patch_list)),
        lib=lib,
    )
    setup_flaggems_logging(path=path, record=record, once=once)


class use_gems:
    def __init__(self, unused=None, record=False, once=False, path=None):
        self.lib = torch.library.Library("aten", "IMPL")
        self.unused = [] if unused is None else unused
        self.registrar = Register
        self.record = record
        self.once = once
        self.path = path

    def __enter__(self):
        enable(
            lib=self.lib,
            unused=self.unused,
            registrar=self.registrar,
            record=self.record,
            once=self.once,
            path=self.path,
        )

    def __exit__(self, exc_type, exc_val, exc_tb):
        global current_work_registrar
        if torch.__version__ >= "2.5":
            self.lib._destroy()
        del self.lib
        del self.unused
        del self.registrar
        del current_work_registrar
        if self.record:
            for handler in logging.root.handlers[:]:
                logging.root.removeHandler(handler)
            logging.basicConfig(level=logging.INFO)

    @property
    def experimental_ops(self):
        import flag_gems.experimental_ops

        return flag_gems.experimental_ops


def all_ops():
    return current_work_registrar.get_all_ops()


__all__ = [
    "enable",
    "use_gems",
]
