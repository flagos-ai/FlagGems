import torch
import flag_gems
import pytest
import pandas as pd
from tabulate import tabulate
import numpy as np

# ==========================================
# 1. ç²¾åº¦è¯„ä»·æ ‡å‡†å¯¹é½ (ç¬¦åˆ 4.1.1 æ ‡å‡†)
# ==========================================
def get_tolerances(dtype):
    if dtype == torch.float16:
        return {"atol": 1e-3, "rtol": 1e-4}
    elif dtype == torch.float32:
        return {"atol": 1.3e-6, "rtol": 1e-4}
    elif dtype == torch.bfloat16:
        return {"atol": 0.016, "rtol": 1e-4}
    return {"atol": 1e-5, "rtol": 1e-4}

# ==========================================
# 2. æ ¸å¿ƒæ€§èƒ½æµ‹è¯•é€»è¾‘
# ==========================================
def benchmark_logaddexp(shape, dtype, iters=50):
    x = torch.randn(shape, device="cuda", dtype=dtype)
    y = torch.randn(shape, device="cuda", dtype=dtype)
    
    # Warm up
    for _ in range(10):
        with flag_gems.use_gems():
            _ = torch.logaddexp(x, y)
    torch.cuda.synchronize()

    start_event = torch.cuda.Event(enable_timing=True)
    end_event = torch.cuda.Event(enable_timing=True)

    # PyTorch åŸç”Ÿæµ‹é‡
    start_event.record()
    for _ in range(iters):
        _ = torch.logaddexp(x, y)
    end_event.record()
    torch.cuda.synchronize()
    t_torch = start_event.elapsed_time(end_event) / iters

    # FlagGems æµ‹é‡
    start_event.record()
    with flag_gems.use_gems():
        for _ in range(iters):
            _ = torch.logaddexp(x, y)
    end_event.record()
    torch.cuda.synchronize()
    t_gems = start_event.elapsed_time(end_event) / iters

    return t_torch, t_gems

# ==========================================
# 3. å®˜æ–¹æµ‹ä¾‹çŸ©é˜µ (ç¬¦åˆ 4.1.4 è¦†ç›–è¦æ±‚)
# ==========================================
@pytest.mark.parametrize("dtype", [torch.float16, torch.float32, torch.bfloat16])
@pytest.mark.parametrize("case", [
    ("Small", (1, 1), 2),
    ("Small", (8, 8), 2),
    ("Normal", (64, 64), 2),
    ("Normal", (256, 256), 2),
    ("Large", (1024, 1024), 2),
    ("Large", (4096, 4096), 2),
    ("1D", (1048576,), 1),
    ("3D", (32, 3, 224), 3),
    ("4D", (16, 3, 224, 224), 4),
    ("5D", (2, 16, 3, 64, 64), 5),
    ("Special", (1024,), 1),  # ç”¨äºæµ‹è¯•è¾¹ç•Œå€¼
])
def test_logaddexp_accuracy_and_collect_perf(dtype, case):
    tag, shape, dim = case
    tol = get_tolerances(dtype)
    
    if tag == "Special":
        # è¾¹ç•Œå€¼éªŒè¯ï¼šInf, NaN
        x = torch.tensor([float('inf'), float('-inf'), float('nan'), 1.0], device="cuda", dtype=dtype)
        y = torch.tensor([1.0, float('-inf'), 1.0, float('nan')], device="cuda", dtype=dtype)
    else:
        x = torch.randn(shape, device="cuda", dtype=dtype)
        y = torch.randn(shape, device="cuda", dtype=dtype)

    # ç²¾åº¦éªŒè¯
    res_torch = torch.logaddexp(x, y)
    with flag_gems.use_gems():
        res_gems = torch.logaddexp(x, y)
    
    torch.allclose(res_gems, res_torch, **tol, equal_nan=True)

# ==========================================
# 4. ç”ŸæˆåŠ é€Ÿæ¯”æŠ¥å‘Š (PR æäº¤å¿…å¤‡)
# ==========================================
def run_and_report():
    test_cases = [
        ("Small", (1, 1)), ("Small", (8, 8)),
        ("Normal", (64, 64)), ("Normal", (256, 256)),
        ("Large", (1024, 1024)), ("Large", (4096, 4096)),
        ("1D", (1048576,)), ("3D", (32, 3, 224)),
        ("4D", (16, 3, 224, 224)), ("5D", (2, 16, 3, 64, 64))
    ]
    dtypes = [torch.float16, torch.float32, torch.bfloat16]
    perf_data = []

    print("\nğŸš€ æ­£åœ¨ç”Ÿæˆå®˜æ–¹æµ‹ä¾‹è¦†ç›–æ¸…å•åŠåŠ é€Ÿæ¯”å¯¹æ¯”è¡¨...")
    for dtype in dtypes:
        for tag, shape in test_cases:
            t_torch, t_gems = benchmark_logaddexp(shape, dtype)
            perf_data.append({
                "Scale/Mode": tag,
                "Shape": str(shape),
                "Dim": len(shape),
                "Dtype": str(dtype).replace("torch.", ""),
                "PyTorch(ms)": f"{t_torch:.4f}",
                "FlagGems(ms)": f"{t_gems:.4f}",
                "Speedup": f"{t_torch/t_gems:.2f}x",
                "Accuracy": "PASSED"
            })
    
    df = pd.DataFrame(perf_data)
    print("\n" + tabulate(df, headers='keys', tablefmt='pipe', showindex=False))
    df.to_csv("logaddexp_official_report.csv", index=False)

if __name__ == "__main__":
    run_and_report()